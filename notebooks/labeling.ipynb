{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a9718f93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ProtocolError('Connection aborted.', ConnectionResetError(10054, 'An existing connection was forcibly closed by the remote host', None, 10054, None))': /simple/tokenizers/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Collecting transformers\n",
      "  Downloading transformers-4.48.1-py3-none-any.whl (9.7 MB)\n",
      "     ---------------------------------------- 9.7/9.7 MB 18.5 kB/s eta 0:00:00\n",
      "Collecting tokenizers<0.22,>=0.21\n",
      "  Downloading tokenizers-0.21.0-cp39-abi3-win_amd64.whl (2.4 MB)\n",
      "     ---------------------------------------- 2.4/2.4 MB 18.9 kB/s eta 0:00:00\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (1.21.5)\n",
      "Requirement already satisfied: filelock in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (3.6.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (4.64.1)\n",
      "Requirement already satisfied: requests in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (2.28.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (21.3)\n",
      "Collecting safetensors>=0.4.1\n",
      "  Using cached safetensors-0.5.2-cp38-abi3-win_amd64.whl (303 kB)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (2022.7.9)\n",
      "Collecting huggingface-hub<1.0,>=0.24.0\n",
      "  Using cached huggingface_hub-0.27.1-py3-none-any.whl (450 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.3.0)\n",
      "Collecting fsspec>=2023.5.0\n",
      "  Using cached fsspec-2024.12.0-py3-none-any.whl (183 kB)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from packaging>=20.0->transformers) (3.0.9)\n",
      "Requirement already satisfied: colorama in c:\\users\\123\\appdata\\roaming\\python\\python39\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->transformers) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->transformers) (1.26.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->transformers) (2022.9.14)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->transformers) (2.0.4)\n",
      "Installing collected packages: safetensors, fsspec, huggingface-hub, tokenizers, transformers\n",
      "Successfully installed fsspec-2024.12.0 huggingface-hub-0.27.1 safetensors-0.5.2 tokenizers-0.21.0 transformers-4.48.1\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f0f00839",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e5289b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the reduced dataset\n",
    "df = pd.read_csv('final_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "93c80a22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing complete! Saved as 'preprocessed_data.csv'.\n"
     ]
    }
   ],
   "source": [
    "# Function to preprocess Amharic text\n",
    "def preprocess_text(text):\n",
    "    if pd.isna(text):\n",
    "        return \"[UNKNOWN]\"  # Handle missing values\n",
    "    \n",
    "    # Normalize text (remove diacritics, links, and emojis)\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)  # Remove punctuation\n",
    "    text = re.sub(r'https?://\\S+', '', text)  # Remove URLs\n",
    "    text = re.sub(r'[^\\u1200-\\u137F\\s]', '', text)  # Remove non-Amharic characters\n",
    "    \n",
    "    # Tokenize (split text into words)\n",
    "    tokens = text.split()\n",
    "    return \" \".join(tokens)  # Join tokens with spaces for compatibility\n",
    "\n",
    "# Apply preprocessing to the Message column\n",
    "df['Preprocessed Message'] = df['Message'].apply(preprocess_text)\n",
    "\n",
    "# Save the preprocessed dataset\n",
    "df.to_csv('preprocessed_data.csv', index=False)\n",
    "print(\"Preprocessing complete! Saved as 'preprocessed_data.csv'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee95bfe1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Channel Title</th>\n",
       "      <th>Channel Username</th>\n",
       "      <th>ID</th>\n",
       "      <th>Message</th>\n",
       "      <th>Date</th>\n",
       "      <th>Media Path</th>\n",
       "      <th>Preprocessed Message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SINA KIDS/áˆ²áŠ“ áŠªá‹µáˆµâ“‡</td>\n",
       "      <td>@sinayelj</td>\n",
       "      <td>15344</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2025-01-20 05:23:15+00:00</td>\n",
       "      <td>@sinayelj_15344.jpg</td>\n",
       "      <td>[UNKNOWN]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SINA KIDS/áˆ²áŠ“ áŠªá‹µáˆµâ“‡</td>\n",
       "      <td>@sinayelj</td>\n",
       "      <td>15343</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2025-01-20 05:23:15+00:00</td>\n",
       "      <td>@sinayelj_15343.jpg</td>\n",
       "      <td>[UNKNOWN]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SINA KIDS/áˆ²áŠ“ áŠªá‹µáˆµâ“‡</td>\n",
       "      <td>@sinayelj</td>\n",
       "      <td>15342</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2025-01-20 05:23:15+00:00</td>\n",
       "      <td>@sinayelj_15342.jpg</td>\n",
       "      <td>[UNKNOWN]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SINA KIDS/áˆ²áŠ“ áŠªá‹µáˆµâ“‡</td>\n",
       "      <td>@sinayelj</td>\n",
       "      <td>15341</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2025-01-20 05:23:15+00:00</td>\n",
       "      <td>@sinayelj_15341.jpg</td>\n",
       "      <td>[UNKNOWN]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SINA KIDS/áˆ²áŠ“ áŠªá‹µáˆµâ“‡</td>\n",
       "      <td>@sinayelj</td>\n",
       "      <td>15340</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2025-01-20 05:23:15+00:00</td>\n",
       "      <td>@sinayelj_15340.jpg</td>\n",
       "      <td>[UNKNOWN]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10903</th>\n",
       "      <td>Sheger online-store</td>\n",
       "      <td>@Shageronlinestore</td>\n",
       "      <td>12</td>\n",
       "      <td>ğŸ¯ Kitchen Sticker\\n\\náˆˆáŠªá‰½áŠ•á‹ á‹á‰ á‰µ áŠ¥áŒ…áŒ á‰°áˆ˜áˆ«áŒ­ \\nğŸ”°á‹áˆ€ ...</td>\n",
       "      <td>2021-04-27 05:58:59+00:00</td>\n",
       "      <td>@Shageronlinestore_12.jpg</td>\n",
       "      <td>áˆˆáŠªá‰½áŠ•á‹ á‹á‰ á‰µ áŠ¥áŒ…áŒ á‰°áˆ˜áˆ«áŒ­ á‹áˆ€ á‹¨áˆ›á‹«áˆµáŒˆá‰£ á‰…á‰£á‰µ á‹˜á‹­á‰µ áŠáŒˆáˆ®á‰½ á‹¨áˆ›á‹«á‰ ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10904</th>\n",
       "      <td>Sheger online-store</td>\n",
       "      <td>@Shageronlinestore</td>\n",
       "      <td>10</td>\n",
       "      <td>ğŸ¯ 3in1 One Step Hair Dryer &amp; Styler \\n\\nğŸ‘‰ áŠ¨áˆ­áˆ ...</td>\n",
       "      <td>2021-04-27 05:57:12+00:00</td>\n",
       "      <td>@Shageronlinestore_10.jpg</td>\n",
       "      <td>áŠ¨áˆ­áˆ áˆˆáˆ˜áˆµáˆ«á‰µ áˆˆáˆ›áˆˆáˆµáˆˆáˆµ áŠ¥áŠ•á‹²áˆáˆ áˆˆáˆ›á‹µáˆ¨á‰… á‹¨áˆšá‹«áŒˆáˆˆáŒáˆ áˆˆáŠ¢á‰µá‹®áŒµá‹«á‹á‹«áŠ•...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10905</th>\n",
       "      <td>Sheger online-store</td>\n",
       "      <td>@Shageronlinestore</td>\n",
       "      <td>9</td>\n",
       "      <td>âœ… Home GYM - X5 slimming vibrator \\n\\nğŸ“¢ğŸ“¢ğŸ“¢ á‰³áˆ‹á‰… ...</td>\n",
       "      <td>2021-04-27 05:45:57+00:00</td>\n",
       "      <td>@Shageronlinestore_9.jpg</td>\n",
       "      <td>á‰³áˆ‹á‰… á‰…áŠ“áˆ½ á‹¨áˆ°á‹‰áŠá‰µá‹ á‹ááˆ¨á‰µ áŠ áˆ³áˆµá‰§á‰³áˆ áˆ™áˆ‰ á‰ áˆ™áˆ‰ á‰¦áˆ­áŒ­áŠ• á‰ áŠ áŒ­áˆ­ áŒŠá‹œ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10906</th>\n",
       "      <td>Sheger online-store</td>\n",
       "      <td>@Shageronlinestore</td>\n",
       "      <td>3</td>\n",
       "      <td>#Finger_tip_pulse_oximeter\\n       #á‰ á‰°áˆ˜áŒ£áŒ£áŠ_á‹‹áŒ‹\\...</td>\n",
       "      <td>2021-04-12 08:35:47+00:00</td>\n",
       "      <td>@Shageronlinestore_3.jpg</td>\n",
       "      <td>á‰ á‰°áˆ˜áŒ£áŒ£áŠá‹‹áŒ‹ áˆˆáŠ áŒ á‰ƒá‰€áˆ áˆá‰¹ á‰ áˆ°á‹‰áŠá‰³á‰½áŠ• á‹«áˆˆá‹áŠ• á‹¨áŠ¦áŠ­áˆµáŒ…áŠ• áŠ¥áŠ“ á‹¨áˆá‰¥ ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10907</th>\n",
       "      <td>Sheger online-store</td>\n",
       "      <td>@Shageronlinestore</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021-04-11 10:31:03+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[UNKNOWN]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10908 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Channel Title    Channel Username     ID  \\\n",
       "0        SINA KIDS/áˆ²áŠ“ áŠªá‹µáˆµâ“‡           @sinayelj  15344   \n",
       "1        SINA KIDS/áˆ²áŠ“ áŠªá‹µáˆµâ“‡           @sinayelj  15343   \n",
       "2        SINA KIDS/áˆ²áŠ“ áŠªá‹µáˆµâ“‡           @sinayelj  15342   \n",
       "3        SINA KIDS/áˆ²áŠ“ áŠªá‹µáˆµâ“‡           @sinayelj  15341   \n",
       "4        SINA KIDS/áˆ²áŠ“ áŠªá‹µáˆµâ“‡           @sinayelj  15340   \n",
       "...                    ...                 ...    ...   \n",
       "10903  Sheger online-store  @Shageronlinestore     12   \n",
       "10904  Sheger online-store  @Shageronlinestore     10   \n",
       "10905  Sheger online-store  @Shageronlinestore      9   \n",
       "10906  Sheger online-store  @Shageronlinestore      3   \n",
       "10907  Sheger online-store  @Shageronlinestore      1   \n",
       "\n",
       "                                                 Message  \\\n",
       "0                                                    NaN   \n",
       "1                                                    NaN   \n",
       "2                                                    NaN   \n",
       "3                                                    NaN   \n",
       "4                                                    NaN   \n",
       "...                                                  ...   \n",
       "10903  ğŸ¯ Kitchen Sticker\\n\\náˆˆáŠªá‰½áŠ•á‹ á‹á‰ á‰µ áŠ¥áŒ…áŒ á‰°áˆ˜áˆ«áŒ­ \\nğŸ”°á‹áˆ€ ...   \n",
       "10904  ğŸ¯ 3in1 One Step Hair Dryer & Styler \\n\\nğŸ‘‰ áŠ¨áˆ­áˆ ...   \n",
       "10905  âœ… Home GYM - X5 slimming vibrator \\n\\nğŸ“¢ğŸ“¢ğŸ“¢ á‰³áˆ‹á‰… ...   \n",
       "10906  #Finger_tip_pulse_oximeter\\n       #á‰ á‰°áˆ˜áŒ£áŒ£áŠ_á‹‹áŒ‹\\...   \n",
       "10907                                                NaN   \n",
       "\n",
       "                            Date                 Media Path  \\\n",
       "0      2025-01-20 05:23:15+00:00        @sinayelj_15344.jpg   \n",
       "1      2025-01-20 05:23:15+00:00        @sinayelj_15343.jpg   \n",
       "2      2025-01-20 05:23:15+00:00        @sinayelj_15342.jpg   \n",
       "3      2025-01-20 05:23:15+00:00        @sinayelj_15341.jpg   \n",
       "4      2025-01-20 05:23:15+00:00        @sinayelj_15340.jpg   \n",
       "...                          ...                        ...   \n",
       "10903  2021-04-27 05:58:59+00:00  @Shageronlinestore_12.jpg   \n",
       "10904  2021-04-27 05:57:12+00:00  @Shageronlinestore_10.jpg   \n",
       "10905  2021-04-27 05:45:57+00:00   @Shageronlinestore_9.jpg   \n",
       "10906  2021-04-12 08:35:47+00:00   @Shageronlinestore_3.jpg   \n",
       "10907  2021-04-11 10:31:03+00:00                        NaN   \n",
       "\n",
       "                                    Preprocessed Message  \n",
       "0                                              [UNKNOWN]  \n",
       "1                                              [UNKNOWN]  \n",
       "2                                              [UNKNOWN]  \n",
       "3                                              [UNKNOWN]  \n",
       "4                                              [UNKNOWN]  \n",
       "...                                                  ...  \n",
       "10903  áˆˆáŠªá‰½áŠ•á‹ á‹á‰ á‰µ áŠ¥áŒ…áŒ á‰°áˆ˜áˆ«áŒ­ á‹áˆ€ á‹¨áˆ›á‹«áˆµáŒˆá‰£ á‰…á‰£á‰µ á‹˜á‹­á‰µ áŠáŒˆáˆ®á‰½ á‹¨áˆ›á‹«á‰ ...  \n",
       "10904  áŠ¨áˆ­áˆ áˆˆáˆ˜áˆµáˆ«á‰µ áˆˆáˆ›áˆˆáˆµáˆˆáˆµ áŠ¥áŠ•á‹²áˆáˆ áˆˆáˆ›á‹µáˆ¨á‰… á‹¨áˆšá‹«áŒˆáˆˆáŒáˆ áˆˆáŠ¢á‰µá‹®áŒµá‹«á‹á‹«áŠ•...  \n",
       "10905  á‰³áˆ‹á‰… á‰…áŠ“áˆ½ á‹¨áˆ°á‹‰áŠá‰µá‹ á‹ááˆ¨á‰µ áŠ áˆ³áˆµá‰§á‰³áˆ áˆ™áˆ‰ á‰ áˆ™áˆ‰ á‰¦áˆ­áŒ­áŠ• á‰ áŠ áŒ­áˆ­ áŒŠá‹œ...  \n",
       "10906  á‰ á‰°áˆ˜áŒ£áŒ£áŠá‹‹áŒ‹ áˆˆáŠ áŒ á‰ƒá‰€áˆ áˆá‰¹ á‰ áˆ°á‹‰áŠá‰³á‰½áŠ• á‹«áˆˆá‹áŠ• á‹¨áŠ¦áŠ­áˆµáŒ…áŠ• áŠ¥áŠ“ á‹¨áˆá‰¥ ...  \n",
       "10907                                          [UNKNOWN]  \n",
       "\n",
       "[10908 rows x 7 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "97532a91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversion to CoNLL format complete! Saved as 'data_conll.txt'.\n"
     ]
    }
   ],
   "source": [
    "# Convert dataset to CoNLL format\n",
    "with open('data_conll.txt', 'w', encoding='utf-8') as f:\n",
    "    for _, row in df.iterrows():\n",
    "        text = row['Preprocessed Message']\n",
    "        tokens = text.split()\n",
    "        \n",
    "        for token in tokens:\n",
    "            f.write(f\"{token} O\\n\")  # Default label is \"O\"\n",
    "        \n",
    "        f.write(\"\\n\")  # Separate sentences/messages with a blank line\n",
    "\n",
    "print(\"Conversion to CoNLL format complete! Saved as 'data_conll.txt'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "047f4cb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3e0a9f335154083a1700c4b30551b73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/852 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\123\\AppData\\Roaming\\Python\\Python39\\site-packages\\huggingface_hub\\file_download.py:140: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\123\\.cache\\huggingface\\hub\\models--xlm-roberta-large-finetuned-conll03-english. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cde25a13b8064697bea91d9ef2fb04de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/2.24G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFXLMRobertaForTokenClassification.\n",
      "\n",
      "All the weights of TFXLMRobertaForTokenClassification were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFXLMRobertaForTokenClassification for predictions without further training.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9a89dc10a944b93a6a132a5bf7823a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/25.0 [00:03<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "542aa247d193406faf70adc10987b506",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99f1c17234ca409f8080a6f9eace221f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/9.10M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use 0\n"
     ]
    }
   ],
   "source": [
    "# Load a pretrained multilingual model for NER\n",
    "ner_model = pipeline(\"ner\", model=\"xlm-roberta-large-finetuned-conll03-english\")\n",
    "\n",
    "def label_with_pretrained_model(message):\n",
    "    if pd.isna(message) or not message.strip():\n",
    "        return \"\"\n",
    "\n",
    "    labeled_tokens = []\n",
    "    \n",
    "    # Tokenize and predict entities using a pretrained model\n",
    "    entities = ner_model(message)\n",
    "\n",
    "    # Assign labels based on model predictions\n",
    "    for entity in entities:\n",
    "        token = entity['word']\n",
    "        label = entity['entity']  # e.g., \"B-LOC\", \"I-LOC\", \"O\"\n",
    "        labeled_tokens.append(f\"{token} {label}\")\n",
    "\n",
    "    return \"\\n\".join(labeled_tokens)\n",
    "\n",
    "# Apply the function to the dataset\n",
    "df['Labeled_Message'] = df['Message'].apply(label_with_pretrained_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "822ccb42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the labeled dataset\n",
    "df.to_csv('labeled_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ac85f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
